[{"categories":["Kubernetes"],"content":"Kubernetes nginx cache purge 实践.","date":"2020-11-28","objectID":"/kubernetes-nginx/","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"最近项目在对部署在香港节点的网站服务做资源加载提速，本文主要记录了在kubernetes的原生nginx ingress中引入server cache的流程和方案， 里面涉及的都是最为常见的技术，并没有什么新的东西，算是一个总结和记录。 ","date":"2020-11-28","objectID":"/kubernetes-nginx/:0:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"背景和前提 当前已上线的网站都是基于Nginx Ingress + Hugo/Vue Server的模式部署的，发布采用 ArgoCD(GitOps) + Jenkins ,大致的流程如下: ","date":"2020-11-28","objectID":"/kubernetes-nginx/:1:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"准备 Nginx做Server端的缓存目前有2种方式比较常见: 基于外置的中间件做数据缓存，比如Nginx官方Redis Module给出的部署介绍， 这种方式的好处就是: 缓存集中，有利于命中和清理，同时不会增加nginx本身的业务复杂度，但他也有问题，就是会引入部署的成本。 server { location / { set $redis_key $uri; redis_pass name:6379; default_type text/html; error_page 404 = /fallback; } location = /fallback { proxy_pass backend; } } 基于Nginx本身的proxy_cache实现，这个是官方很早就引入的功能，直接利用本地磁盘做缓存存储，考虑到网站本身的规模和系统复杂度, 我们选择了nginx自带的proxy_cache加kubernetes中的memory emptyDir做服务端缓存。 ","date":"2020-11-28","objectID":"/kubernetes-nginx/:2:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"环境准备 Nginx本身已经包含了proxy_cache的模块，不过关于purge的功能却仅在商业版本中才包含，所以我们需要自己引入并制作镜像，下面是社区推荐的第三方 的purge模块: https://github.com/FRiCKLE/ngx_cache_purge 很遗憾他并不支持批量的缓存清除，从README里面的配置指导可以看出，我们需要对缓存的资源进行逐个清除: http { proxy_cache_path /tmp/cache keys_zone=tmpcache:10m; server { location / { proxy_pass http://127.0.0.1:8000; proxy_cache tmpcache; proxy_cache_key $uri$is_args$args; } location ~ /purge(/.*) { allow 127.0.0.1; deny all; proxy_cache_purge tmpcache $1$is_args$args; } } } 而且，这个仓库已经6年没人维护了，好在最近nginx社区自己fork并维护起来了地址， 最关键的是作者还加入了我们正想要的Partial Keys功能 :) 。 Nginx ingress关于怎么制作自定义镜像的指导比较少，不过从Makefile里面能快速搜索到他们的Base Image 而且制作镜像的流程非常清晰，基于现有的流程做扩展和第三方Module引入还是比较方便的。 现有引入的Module: nginx-http-auth-digest ngx_http_substitutions_filter_module nginx-opentracing opentracing-cpp zipkin-cpp-opentracing dd-opentracing-cpp ModSecurity-nginx (only supported in x86_64) brotli geoip2 完整的改动已经放到了我们组织的fork仓库, 需要注意的一个点就是nginx ingress官方为了支持多架构和性能，在构建镜像时引入了buildx组件， 他跟我们原生的docker build有一点区别是他并不会默认导出制作好的镜像，需要我们在命令中具体指明，如: #具体文档，请移步: https://github.com/docker/buildx docker buildx build --output=type=docker . 有了基础镜像，在制作controller的镜像时，只需要将BASE_IMAGE替换为我们生成好的镜像即可, 如: BASE_IMAGE=opensourceways/ingress-nginx-with-purge:0.0.1 make image 有了镜像，可以在镜像中通过nginx -V确认模块以加载: ➜ ~ docker run -it --rm opensourceway/ingress-nginx-controller-with-purge-cache:v0.35.0.0 nginx -V nginx version: nginx/1.19.2 built by gcc 9.3.0 (Alpine 9.3.0) built with OpenSSL 1.1.1g 21 Apr 2020 TLS SNI support enabled \u003ccontent skipped\u003e --add-module=/tmp/build/ngx_devel_kit-0.3.1 --add-module=/tmp/build/set-misc-nginx-module-0.32 --add-module=/tmp/build/headers-more-nginx-module-0.33 --add-module=/tmp/build/nginx-http-auth-digest-cd8641886c873cf543255aeda20d23e4cd603d05 --add-module=/tmp/build/ngx_http_substitutions_filter_module-bc58cb11844bc42735bbaef7085ea86ace46d05b --add-module=/tmp/build/lua-nginx-module-0.10.17 --add-module=/tmp/build/stream-lua-nginx-module-0.0.8 --add-module=/tmp/build/lua-upstream-nginx-module-0.07 --add-module=/tmp/build/nginx-influxdb-module-5b09391cb7b9a889687c0aa67964c06a2d933e8b --add-dynamic-module=/tmp/build/nginx-opentracing-0.9.0/opentracing --add-dynamic-module=/tmp/build/ModSecurity-nginx-b55a5778c539529ae1aa10ca49413771d52bb62e --add-dynamic-module=/tmp/build/ngx_http_geoip2_module-3.3 --add-module=/tmp/build/nginx_ajp_module-bf6cd93f2098b59260de8d494f0f4b1f11a84627 --add-module=/tmp/build/ngx_brotli --add-module=/tmp/build/ngx_cache_purge-2.5.1 有了镜像，下一步就是配置了。 ","date":"2020-11-28","objectID":"/kubernetes-nginx/:3:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"主要配置 proxy_cache_path: Syntax: proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [min_free=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; Default: — Context: http 这个是cache的全局配置，其中几个比较重要的字段介绍如下: path: 缓存的配置路径 keys_zone:\u003cname:size\u003e: 缓存的key区域，当开启某个domain的访问缓存时，使用proxy_cache指定对应的key_zone, 注意缓存的key是存储在内存中的，所以需要指定存储的上限，根据官方文档，1mb基本可以存储8k个key。 use_temp_path：是否启用temp目录用于上游返回内容的保存，nginx的cache在开启temp_path的时候会有2步，保存结果到temp目录，拷贝到cache目录，建议关闭。 inactive: 缓存的保留时间retention, 如果超过时间资源没有被访问，缓存将被清除。 max_size: 缓存数据的最大占用空间，超出后空间将被清理(基于最近最少使用原则)， levels + proxy_cache_key: 这2个字段配合起来，决定了我们缓存存储的路径，其中level决定了存储的目录层级以及目录名，cache_key决定了最终的文件名，举个例子，比如我的配置如下： proxy_cache_key $uri$is_args$args; proxy_cache_path /tmp/statics_cache levels=1:2 keys_zone=statics_cache:50m use_temp_path=off max_size=500m inactive=1h; 当我们访问http://somedomain.com/public/img/grafana_icon.svg的时候，对proxy_cache_key(/img/grafana_icon.svg)进行MD5计算，得: ➜ ~ md5 -s \"/public/img/grafana_icon.svg\" MD5 (\"/public/img/grafana_icon.svg\") = e07fe02651e785ebf74c2c5c0abae094 那我们最终的存储路径就是:/tmp/statics_cache/4/09/e07fe02651e785ebf74c2c5c0abae094, 其中目录信息反向截图。 proxy_cache_lock: cache锁，在多个请求访问同样资源，且开启cache的情况下，只有一个请求有权限去生成cache或访问cache。 proxy_cache_valid: cache的有效时间，超期的缓存将从上游重新获取， 我们可以基于返回结果做差异化配置，比如proxy_cache_valid 404 1m;设置404近保留1分钟。 proxy_ignore_headers：忽略响应中的某些header，比如: proxy_ignore_headers Cache-Control就能忽略上游的缓存策略，避免对我们的server cache造成影响。 proxy_cache_methods: 缓存的http方法，默认会包含GET和HEAD。 proxy_cache_min_uses: 设置资源访问多少次后再缓存，提高阈值能确保高频率的资源被缓存和使用。 基于上面的配置，我们就能在nginx-ingress中configmap中引入http-snippet， 修改deployment确保emptyDir挂载: apiVersion: v1 data: http-snippet: | proxy_cache_path /tmp/statics_cache levels=1:2 keys_zone=statics_cache:50m use_temp_path=off max_size=500m inactive=1h; kind: ConfigMap metadata: name: nginx-configuration namespace: ingress-nginx # other attribute in deployment are ignored. volumes: - name: nginx-proxy-cache emptyDir: medium: Memory sizeLimit: \"500Mi\" ","date":"2020-11-28","objectID":"/kubernetes-nginx/:4:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"启用cache 当需要网站的server cache时，需要在具体的Ingress中做如下配置: nginx.ingress.kubernetes.io/proxy-buffering: \"on\" nginx.ingress.kubernetes.io/server-snippet: | proxy_cache statics_cache; proxy_cache_lock on; proxy_cache_key $server_name$uri$is_args$args; proxy_ignore_headers Cache-Control; proxy_ignore_headers Set-Cookie; proxy_cache_valid 60m; add_header X-Cache-Status $upstream_cache_status; location ~ /purge(/.*) { allow 127.0.0.1; allow 172.20.0.0/16; deny all; proxy_cache_purge statics_cache $server_name$1$is_args$args; } 说明如下： proxy_buffering： 这个是开启缓存的前提，nginx ingress默认是关闭的。 add_header: 在返回的Header中添加cache status (MISS,HIT,EXPIRED)，用于查看缓存命中情况，如果我们在location server等多处有定义add_header, 需要注意的一点是: # from nginx document There could be several add_header directives. These directives are inherited from the previous configuration level if and only if there are no add_header directives defined on the current level. proxy_cache_key: 在nginx ingress中我们一般会服务多个domain，所以这里的key需要引入server_name避免相互干扰。 ","date":"2020-11-28","objectID":"/kubernetes-nginx/:5:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"开启Purge 首先并不是所有的情况下都需要purge，毕竟现在有很多解决方案可以确保版本更新后缓存自动失效. 比如在生成资源时对文件名做hash: zh-cn_image_0183048952.d04e2e5f.png 或者是在请求中带上发布版本的版本号参数: /abc.css?v=20201012 这些都会导致缓存的key失效，从而避免干扰，不过我们并不能保证所有的情况下都能满足，所以需要支持通过API调用清理失效的缓存，purge模块支持我们配置单独的API用于网站缓存资源清理(前缀匹配): location ~ /purge(/.*) { allow 127.0.0.1 allow 172.20.0.0/16; deny all; proxy_cache_purge statics_cache $server_name$1$is_args$args; } 上面的配置段需要同样添加到server-snippet中，且仅支持内网访问，注意：proxy_cache_purge的key需要跟proxy_cache_key保持一致。 我们通过API测试，结果是some-domain的缓存资源都会被清除: $: curl -H \"Host:some-domain\" -k https://\u003cnginx-endpoint\u003e/purge/* \u003chtml\u003e \u003chead\u003e\u003ctitle\u003eSuccessful purge\u003c/title\u003e\u003c/head\u003e \u003cbody bgcolor=\"white\"\u003e\u003ccenter\u003e\u003ch1\u003eSuccessful purge\u003c/h1\u003e\u003cp\u003eKey : some-domain/*\u003c/p\u003e\u003c/center\u003e\u003c/body\u003e \u003c/html\u003e 不过，我们还有一个问题: nginx ingress都是多实例的，清理单个实例还不够，当前原生的Kubernetes中并没有类似的概念可以支持我们一次性清理，只能考虑将purge的请求复制多份到endpoints分别处理, 大致的逻辑如下Stackoverflow: TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token); curl https://kubernetes.default.svc/api/v1/namespaces/default/endpoints --silent \\ --header \"Authorization: Bearer $TOKEN\" --insecure | jq -rM \".items[].subsets[].addresses[].ip\" | xargs curl 我们搭建了一个Basic Auth的Http Server用于响应流水线中的清除缓存动作。 有了他我们就差最后一步，跟发布的流水线对接, 前文有提到我们的发布流程是基于Jenkins + ArgoCD实现的， 考虑到ArgoCD本身就有Webhook机制，所以我们的应用的部署代码仓库需要新增如下资源: ","date":"2020-11-28","objectID":"/kubernetes-nginx/:6:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":["Kubernetes"],"content":"触发Purge apiVersion: batch/v1 kind: Job metadata: name: website-nginx-purge annotations: argocd.argoproj.io/hook: PostSync argocd.argoproj.io/hook-delete-policy: BeforeHookCreation spec: ttlSecondsAfterFinished: 600 template: spec: containers: - name: purge-trigger image: curlimages/curl:7.72.0 env: - name: USERNAME valueFrom: secretKeyRef: key: username name: purge-secrets - name: PASSWORD valueFrom: secretKeyRef: key: password name: purge-secrets command: - curl - -u - $(USERNAME):$(PASSWORD) - --fail - https://\u003capi-endpoints\u003e/nginx-purger/purge?hostname=\u003chostname-to-purge\u003e restartPolicy: Never backoffLimit: 2 这样一旦我们更新网站，ArgoCD的Sync行为结束，nginx ingress中的cache就会被自动清除: nginx cache purged for host: some-domain on ingress instance 172.20.0.103 nginx cache purged for host: some-domain on ingress instance 172.20.0.144 nginx cache purged for host: some-domain on ingress instance 172.20.0.56 需要注意的是: argocd.argoproj.io/hook-delete-policy: BeforeHookCreation: 能确保每次synced后Job资源删除后执行。 argo的application不能设置为自动Sync，这样会导致缓存被频繁清除。 全文完。 ","date":"2020-11-28","objectID":"/kubernetes-nginx/:7:0","tags":["ArgoCD","Nginx","Kubernetes"],"title":"Kubernetes nginx ingress cache 实践","uri":"/kubernetes-nginx/"},{"categories":null,"content":"About TommyLike","date":"2019-08-02","objectID":"/about/","tags":null,"title":"About TommyLike","uri":"/about/"},{"categories":null,"content":"Work Experience ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"About TommyLike","uri":"/about/"},{"categories":["OpenStack"],"content":"虚拟化简介 ","date":"2016-08-27","objectID":"/kvm/:0:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"什么是虚拟化? 虚拟化（Virtualization）技术最早出现在 20 世纪 60 年代的 IBM 大型机系统，在70年代的 System 370 系列中逐渐流行起来，这些机器通过一种叫虚拟机监控器（Virtual Machine Monitor，VMM）的程序在物理硬件之上生成许多可以运行独立操作系统软件的虚拟机（Virtual Machine）实例。随着近年多核系统、集群、网格甚至云计算的广泛部署，虚拟化技术在商业应用上的优势日益体现，不仅降低了 IT 成本，而且还增强了系统安全性和可靠性，虚拟化的概念也逐渐深入到人们日常的工作与生活中。 计算机的系统结构如上图所示，在硬件层和操作系统层之间，我们有一个硬件抽象层，他是操作系统实际交互的系统层。利用这个交互层，我们就可以通过软件，模拟返回上层需要的数据，达到虚拟化的目的。 ","date":"2016-08-27","objectID":"/kvm/:1:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"虚拟化的实现方式 虚拟化有两种实现方式,一种是直接运行在硬件平台上，通知所有的硬件并管理客户系统，比如:Xen，一种是运行在传统的操作系统中，类似于在软件层面中提供虚拟环境，比如KVM和VirtualBox ","date":"2016-08-27","objectID":"/kvm/:2:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"虚拟化的平台类型 ","date":"2016-08-27","objectID":"/kvm/:3:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"全虚拟化 全虚拟化是指虚拟机模拟了完整的底层硬件，包括处理器、物理内存、时钟、外设等，使得为原始硬件设计的操作系统或其它系统软件完全不做任何修改就可以在虚拟机中运行。操作系统与真实硬件之间的交互可以看成是通过一个预先规定的硬件接口进行的。全虚拟化 VMM 以完整模拟硬件的方式提供全部接口（同时还必须模拟特权指令的执行过程）。这种模式下Guest OS 一般会降级运行(ring1)，当Guest OS需要执行特权指令时，会触发异常，被VMM捕获(ring0)并执行。使用全虚拟化的VMM有:Microsoft Virtual PC、VMware Workstation、Sun Virtual Box、Parallels Desktop for Mac ","date":"2016-08-27","objectID":"/kvm/:3:1","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"超虚拟化 这是一种修改 Guest OS 部分访问特权状态的代码以便直接与 VMM 交互的技术。在超虚拟化虚拟机中，部分硬件接口以软件的形式提供给客户机操作系统，这可以通过 Hypercall（VMM 提供给 Guest OS 的直接调用，与系统调用类似）的方式来提供，比较著名的 VMM 有 Denali、Xen。 ","date":"2016-08-27","objectID":"/kvm/:3:2","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"硬件辅助虚拟化 硬件辅助虚拟化是指借助硬件（主要是主机处理器）的支持来实现高效的全虚拟化。例如有了 Intel-VT 技术的支持，Guest OS 和 VMM 的执行环境自动地完全隔离开来，Guest OS 有自己的“全套寄存器”，可以直接运行在最高级别。因此在上面的例子中，Guest OS 能够执行修改页表的汇编指令。Intel-VT 和 AMD-V 是目前 x86 体系结构上可用的两种硬件辅助虚拟化技术。 ","date":"2016-08-27","objectID":"/kvm/:3:3","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"部分虚拟化 VMM只模拟部分底层硬件，因此客户机操作系统不做修改是无法在虚拟机中运行的，其它程序可能也需要进行修改。在历史上，部分虚拟化是通往全虚拟化道路上的重要里程碑，最早出现在第一代的分时系统 CTSS 和 IBM M44/44X 实验性的分页系统中。 ","date":"2016-08-27","objectID":"/kvm/:3:4","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"操作系统级虚拟化 在传统操作系统中，所有用户的进程本质上是在同一个操作系统的实例中运行，因此内核或应用程序的缺陷可能影响到其它进程。操作系统级虚拟化是一种在服务器操作系统中使用的轻量级的虚拟化技术，内核通过创建多个虚拟的操作系统实例（内核和库）来隔离不同的进程，不同实例中的进程完全不了解对方的存在。比较著名的有 Solaris Container [2]，FreeBSD,Jail和OpenVZ等。 ","date":"2016-08-27","objectID":"/kvm/:3:5","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"虚拟化的核心技术 CPU虚拟化 从Intel 的Vtx技术开始，对现有的CPU进行了扩展，引入了特权级别和非特权级别，从而在硬件上支持虚拟化。 内存虚拟化 I/O虚拟化 网络虚拟化 GPU虚拟化 ","date":"2016-08-27","objectID":"/kvm/:4:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"常见的虚拟软件 VMware VMware是x86的主流虚拟化厂商之一，目前的产品有:VMware ESX Server(直接运行在物理硬件层),VMware Workstation(基于操作系统的虚拟化类型，主要面向Windows和Linux),VMware Fusion(跟Workstation定位一致，面向Mac系统) Microsoft 跟windows系统配合很好，主要有Virtual PC(面向桌面)和Virtual Server(面向服务器) Xen 起源于英国剑桥大学的一个研究项目，基于硬件层的虚拟化软件。 KVM 基于GPL的开源软件，是基于软件层的虚拟化软件，现在他利用Inter VT等技术达到硬件虚拟化，利用QEMU来提供设备虚拟化，所以也可以理解成基于硬件的完全虚拟化软件。 ","date":"2016-08-27","objectID":"/kvm/:5:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"KVM KVM的运行的架构图大致如下: 其中，处理器直接辅助了虚拟化的支持，内存是KVM进行虚拟化，KVM通过 /dev/kvm 设备提供了内存虚拟化。每个客户操作系统都有自己的地址空间，并且是在实例化客户操作系统时映射的。映射给客户操作系统的物理内存实际上是映射给这个进程的虚拟内存。为了支持客户物理地址到主机物理地址的转换，系统维护了一组影子页表（shadow page table）。而I/O通过EQMU进程进行虚拟化，QEMU 是一个平台虚拟化解决方案，允许对一个完整的 PC 环境进行虚拟化（包括磁盘、图形适配器和网络设备）。客户操作系统所生成的任何 I/O 请求都会被中途截获，并重新发送到 QEMU 进程模拟的用户模式中。 ","date":"2016-08-27","objectID":"/kvm/:6:0","tags":["OpenStack","KVM/QEMU"],"title":"虚拟化简介","uri":"/kvm/"},{"categories":["OpenStack"],"content":"reStructuredText入门 ","date":"2016-08-22","objectID":"/rst/:0:0","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"什么是reStructuredText? reStructuredText通常简称为RST,ReST,reST,是Python里面最为常见的文档格式，他跟Markdown一样，语法在很多地方也很类似，如果有过Markdown的写作经验，入门reStructuredText是一件非常容易的事情。 ","date":"2016-08-22","objectID":"/rst/:1:0","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"RST规范 如果你本地没有即时浏览的编辑器，强烈推荐通过Online Editor来快速上手，我们的介绍几乎都是从官方文档移植过来的。目的是便于个人整理和回顾，个人学习还是推荐去官方文档查看。 ","date":"2016-08-22","objectID":"/rst/:2:0","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"文本 加粗和斜体 RST中的加粗和斜体跟Markdown中用法一致都是通过*和**来指定的: *this is italics* **this is bold** 替代文本(interpreted text) 一般配合rst中的描述标记使用，用来做链接，引用，解释等,例如站外链接: please contact email `\u003chttp://username.organisze.org/\u003e`_ Embedded hyperlink 内嵌的外部链接，引用和定义放在一起 `display_text link_address`_ :在引用符中间就是具体的显示字符和链接地址，后面紧跟_, #以下面实际的例子对比Markdown: External hyperlinks, like `Python \u003chttp://www.python.org/\u003e`_. RST External hyperlinks, like [Python](http://www.python.org/). Markdown Hyperlink target 引用和定义分开，可以多次引用，使用_建立对应关系，可用于纸质输出文档，他的效果和我们上面最终的效果一致: External hyperlinks, like Python_. .. _Python: http://www.python.org/ Inline hyperlink 引用文章内部的区域,就类似于url里面的#,语法跟外部target引用一样，只是定义的时候需要使用如下的格式: # 其实就是在定义的时候生成一个带id的div，到时候再通过#指向该区域而已 External hyperlinks, like Python2_. .. _Python2: this is python2 content #RST生成的title默认就带有id，所以可以直接引用title Title link :`This is title`_. This is title ============= 图片引用 简单的图片插入可以使用**::image**,具体参照如下: For instance: .. image:: images/ball1.gif (这里支持相对和绝对路径) 如果需要在inline中使用png图标，可以配合使用||: The |biohazard| symbol must be used on containers used to dispose of medical waste. .. |biohazard| image:: biohazard.png 页脚注释引用 可以使用[index]_: Footnote references, like [5]_. .. [5] A numerical footnote. Note 多个引用支持配置自增长,#是基于已有的footage列表做累加，遇到已有的定义会自动跳过 Footnote references, like footage_1 [#]_. Footnote references, like footage_2 [#]_. .. [1] this is footage 1 .. [#] This is the first one. actual 2 .. [#] This is the second one. actual 3 引证 引证的用法跟页脚注释引用一致: Citation references, like [CIT2002]_. Note that citations may get rearranged, e.g., to the bottom of the \"page\". .. [CIT2002] A citation (as often used in journals). ","date":"2016-08-22","objectID":"/rst/:2:1","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"段落和其他 标题 标题是通过在文字的下面或者上下面增加一行特殊字符表示，字符的长度不能短于文字的长度，可供选择的字符有:= - : ' \" ~ ^ _ * + # \u003c \u003e, 比如: ===== Title ===== Subtitle -------- 虽然RST本身没有规定层级标题的用法，但是python对不同级别的标题还是有建议规范: 1. \\# with overline, for parts 2. \\* with overline, for chapters 3. =, for sections 4. -, for subsections 5. ^, for subsubsections 6. \", for paragraphs 段落 段落不需要缩进，但是新的段落需要空行，如一下面所示: This is a paragraph. This is another paragraph 无序列表 RST中的无序列表跟markdown很像，支持多个不同的符号- * +,符号和内容之前需要有空格: This is a list - item1 - item2 - item3 ","date":"2016-08-22","objectID":"/rst/:2:2","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"有序列表 RST中的有序列表支持使用**#**作为自增长符号: This is sequenced list: 1. item1 2. item2 3. item3 #. item4 定义列表 定义列表在python的documentation中很常见，需要注意的是在定义的内容中需要缩进，不同的内容之间需要有空行: Definition lists: what Definition lists associate a term with a definition. how The term is a one-line phrase, and the definition is one or more paragraphs or body elements, indented relative to the term. Blank lines are not allowed between term and definition. 字段列表 字段列表在form和brief中比较常见，格式跟定义列表很像，区别在于需要以**:**开头: :Authors: Tony J. (Tibs) Ibbs, David Goodger (and sundry other good-natured folks) :Version: 1.0 of 2001/08/08 :Dedication: To my father. 命令选项列表 这个能帮我们快速构建命令行参数文档，需要注意的是在描述和参数中间至少需要两个空格: -a command-line option \"a\" -b file options can have arguments and long descriptions --long options can be long also --input=file long options can also have arguments /V DOS/VMS-style options too ","date":"2016-08-22","objectID":"/rst/:2:3","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"Literal Blocks(Quota Blocks) 这个跟我们的引用区域很像，通过查看生成的html源代码可以看到literal blocks会生成**\u003cpre\u003e标记， 而我们的引用区域是直接生成\u003cblockquota\u003e标签 这个也能方便我们理解他的作用,一般通过::**来标记开始，内容区域需要使用缩进: content below is literal Blocks:: this is content this is also content this is another paragraph 或者通过**\u003e**来表示: content below is literal Blocks:: \u003e this is content 表格 表格的格式如下,跟markdown一样都比较清晰，自己写文档的时候可以直接借助工具生成，不需要手动编辑,在这里推荐Table Generator,不过他目前只是简单支持: +------------+------------+-----------+ | Header 1 | Header 2 | Header 3 | +============+============+===========+ | body row 1 | column 2 | column 3 | +------------+------------+-----------+ | body row 2 | Cells may span columns.| +------------+------------+-----------+ | body row 3 | Cells may | - Cells | +------------+ span rows. | - contain | | body row 4 | | - blocks. | +------------+------------+-----------+ 过渡 即我们html常见的\u003chr\u003e,一般用的很少，在视觉上隔开段落: A transition marker is a horizontal line of 4 or more repeated punctuation characters. ------------ A transition should not begin or end a section or document, nor should two transitions be immediately adjacent. ","date":"2016-08-22","objectID":"/rst/:2:4","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["OpenStack"],"content":"RST文件预览(windows环境) 跟markdown一样，在编写文档的时候，我们也需要能够本地即时预览，在这一点上Sublimetext和他强大的plugin再合适不过了，这里推荐OmniMarkupPreviewer，大部分的markup语言都支持: Markdown reStruecturedText Textile Pod RDoc Org Mode MediaWiki AsciiDoc Literate Haskell WikiCreole 插件支持实时预览,浏览器预览快捷键(Ctrl+Alt+O) ","date":"2016-08-22","objectID":"/rst/:3:0","tags":["OpenStack","Python"],"title":"reStructuredText入门","uri":"/rst/"},{"categories":["Python"],"content":"Python常见特性入门 ","date":"2016-08-14","objectID":"/python-advance/:0:0","tags":["Python"],"title":"Python常见特性入门(一)","uri":"/python-advance/"},{"categories":["Python"],"content":"装饰器 有过AOP编程经历的人对以下的场景肯定都不陌生:我们暴露了API接口给客户端调用，基于运维的考虑，我们需要自动拦截API接口的耗时参数等信息，通常的方式就是在基类中包装一层或者使用拦截器，大致的代码如下: public string WrapExecute(string fake_param) { ExecuteBefore(fake_param); var result = Execute(); ExecuteAfter(result); return result } Python的装饰器天生就可以承担类似的工作,下面是一个简单的装饰器: def execute_before(): print('this is before') def execute_after(): print('this is after') def decorator(func): def wrapper(): execute_before() func() execute_after() return wrapper def execute(): print('this is executing') execute = decorator(execute) 跟我们在其他语言中的用法保持一致，当然我们的python在此之上，还提供了更便捷的方式:@,python中以@开头并紧跟装饰器的名字可理解成给对应的对应的对象使用装饰器，所以，上面的调用方式，可以优化成: @decorator def execute(): pass 通常情况下，被修饰的函数都是带有参数的，为了能在装饰器中获取参数信息，python中引入了可变参数的概念，*args表明所有未被捕获的参数,**kwargs表明所有未被捕获的keyword参数，我们把我们的wrapper函数调整为如下，则能捕获所有类型的参数: de decorator(func) def wrapper(*args, **kwargs) execute_before() func(args, kwargs) execute_after() #other code 还有一种情况，就是我们的装饰器本身是可以支持配置参数的，在这种情况下，我们往往还需要在外面再增加一层，在现在的例子基础上，比如我们需要支持配置日志级别,那代码可调整如下: def outter_wrapper(log_level='info') def decorator(func): def wrapper(): execute_before(log_level) func() execute_after(log_level) return wrapper return decorator @outter_wrapper(log_level='error') def execute(): pass ","date":"2016-08-14","objectID":"/python-advance/:1:0","tags":["Python"],"title":"Python常见特性入门(一)","uri":"/python-advance/"},{"categories":["Python"],"content":"描述器 描述符是一个具有绑定行为的对象属性，其属性的访问被描述符协议方法覆写。这些方法是__get__()、 set()和__delete__()，一个对象中只要包含了这三个方法（至少一个），就称它为描述符。在python的多个特性:属性(特性)/方法/静态方法/类方法中都有应用。 如果一个描述器定义了*get和set*，他就是一个资料描述器(data descriptor),可以用来定义属性。 如果一个描述器只定义了*get*，他就是一个非资料描述器，通常用来定义方法。 以下是一个最基本的描述器的用法(属性): class PropertyDescriptor(object): def __init__(self, value=None): self.value = value def __get__(self, obj, objtype): print('get value') return self.value def __set__(self, obj, value): print('set value') self.value = value class TestClass(object): attr_x = Property(12) 这样每次我们在调用对象attr_x属性的时候，相应的*set和get*函数就会被调用。 实际上，在python中，描述器在被调用的时候根据类型不同，内部具体调用的方法也不一样。 如果调用方为object instance那相当于调用:type(instance).dict[‘x’].get(instance, type(instance)) 如果调用方为type那相当于调用:type(instance).dict[‘x’].get(None, type(instance)) 以上面的代码为例: instance = TestClass() instance.attr_x == type(instance).__dict__['attr_x'].__get__(instance, type(instance)) TestClass.attr_x == TestClass.__dict__['attr_x'].__get__(None, TestClass) ","date":"2016-08-14","objectID":"/python-advance/:2:0","tags":["Python"],"title":"Python常见特性入门(一)","uri":"/python-advance/"},{"categories":["Python"],"content":"特性 Python内建的property能够帮我们快速构建属性，假设我们现在有个Person对象，需要一个adult(成年)属性根据age(年龄)自动计算，那通过property，代码则大致如下: class Person: def __init__(self,age = 1): self.age = age def _is_adult(self): return self.age \u003e= 18 adult = property(_is_adult) tommy = Person(24) print(tommy.adult) #True python的property支持定义属性的读取/修改/删除/文档操作，用法如下: def get_property_x(self): return self.x #other code document_string = 'this is property x' property_x = property(get_property_x,set_property_x,delete_property_x,document_string) ","date":"2016-08-14","objectID":"/python-advance/:2:1","tags":["Python"],"title":"Python常见特性入门(一)","uri":"/python-advance/"},{"categories":["Python"],"content":"函数 Python中的一切资源都是面向对象的，这里也包括函数,我们看一个简单的例子: class TestMethod(object): def hello(self): print('hello world') print(TestMethod.__dict__['hello']) #\u003cfunction TestMethod.hello at 0x01178BB8\u003e 实际上从类中调用TestMethod.hello，返回的是一个unbound对象，而从实例中调用instance.hello返回的是一个bound对象，在这里可以看到更多关于bound/unbound的资料 python中定义类方法和静态方法都是使用描述器和装饰器组合来实现的，具体实现代码参考:link。 类方法 class ClassMethod(object): \"Emulate PyClassMethod_Type() in Objects/funcobject.c\" def __init__(self, f): self.f = f def __get__(self, obj, klass=None): if klass is None: klass = type(obj) def newfunc(*args): return self.f(klass, *args) return newfunc 静态方法 class StaticMethod(object): \"Emulate PyStaticMethod_Type() in Objects/funcobject.c\" def __init__(self, f): self.f = f def __get__(self, obj, objtype=None): return self.f ","date":"2016-08-14","objectID":"/python-advance/:2:2","tags":["Python"],"title":"Python常见特性入门(一)","uri":"/python-advance/"},{"categories":["OpenStack"],"content":"Oslo Message 入门 ","date":"2016-08-03","objectID":"/amqp/:0:0","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"什么是AMQP? AMQP(Advanced Message Queuing Protocol)是一个异步消息传递所使用的开方的应用层协议规范，主要包括了消息的导向，队列，路由，可靠性和安全性。通过定义消息在网络上传输的字节流格式，不同的具体AMQP实现之间可以进行互操作。 The Advanced Message Queuing Protocol (AMQP) is an open standard application layer protocol for message-oriented middleware. The defining features of AMQP are message orientation, queuing, routing (including point-to-point and publish-and-subscribe), reliability and security 他大体的结构如上所示,包括几个重要的元素: Publisher，即我们的消息发送方。 Broker/Server，服务中间件(转发消息，确定映射规则，存储消息等)。 Subscriber，消息的接收和订阅方。 Exchange，负责将不同的消息送达到不同Subscriber的Queue上，同一个Exchange可以有多个Queue。 Queue，接收方的消息队列，用来保存来不及处理的信息。 Routing Key，消息携带的路由信息，决定了消息可以送到哪些接收方。 Binding Key，Queue的路由信息，决定了Queue可以接收哪些信息。 Exchange Type,交换类型，决定了消息转发的具体匹配模式，有三种模式: Direct:单一的匹配模式，类似于通过id直接指定接收方。 Topic:正则的匹配模式，符合正则匹配的Queue都能收到该消息。 Fanout:广播模式，所有的都能收到。 AMQP只是一个通用的协议，在此协议上有不同实现的服务中间件，比较常见的有以下几种: RabbitMQ(主页) Qpid(主页) ZeroMQ(主页) Kombu(主页) 我们这里使用RabbitMQ作为我们的中间件实现。 ","date":"2016-08-03","objectID":"/amqp/:1:0","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"RabbitMQ ","date":"2016-08-03","objectID":"/amqp/:2:0","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"环境准备 官网上面可以很方面找到下载的操作指导，这里以我们的环境为例，下载完成后，需要把压缩包解压到我们的安装目录,运行前可以在配置文件中进行简单的配置调整: $RABBITMQ_HOME/etc/rabbitmq/rabbitmq-env.conf 执行脚本sbin/rabbitmq-server，服务即可拉起: #以后台进程的方式拉起 rabbitmq-server -detached #暂停服务 rabbitmqctl stop #查看服务状态 rabbitmqctl status 服务拉起后，就可以配置和使用message了。 ","date":"2016-08-03","objectID":"/amqp/:2:1","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"OSLO.Message ","date":"2016-08-03","objectID":"/amqp/:3:0","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"基本概念 开始前，我们也需要了解message里面几个重要的概念，他们跟AMQP里面的概念是一一对应的: 1.Transport 传输层，可以通过URI来获得不同的transport实现句柄，我们可以把rabbitmq/qpid这些理解成不同的传输层(transports)，URI的具体格式如下: transport://user:password@host1:port1[,host2:port2][,hostN:portN]/virtual_host 比如我们现在是使用rabbitmq，那URI就大致如下: rabbit://admin:password@127.0.0.1:8888/ 2.Target 封装了描述最终目的地的所有信息，有以下几个字段: exchange,指明能处理的topic范围，不指定则默认使用配置文件中的control_exchange配置 。 topic,服务端和消息都会使用，用来表明发送和可以接受的主题(组)，例如:topic.subtopic。 namespace,服务可以在一个topic上，提供多种方法集合， 这些方法集合通过namespace来分开管理，可以理解成topic的一个子集。 server,客户端可以通过该字段指定具体的某一台服务器，而不是符合这个topic的任意一台。 fanout,指明时，会发送到这个topic下面所有的服务端。 3.Server Server，为各个Client提供RPC接口,它是消息的最终处理者，单个Server上面可以绑定多个EndPoints。 4.RPC Client 远程调用的客户端，调用是需要指定具体的方法和参数，现在支持两种: cast:异步调用，调用后马上返回 call:同步调用，调用后需要等待结果返回 5.Notifier Listener Notifier Listener与Server一致，不同的地方在于下面挂载的Endpoints暴露的接口名需要与消息不同的优先级保持一致，例如: class NotificationEndpoint(object): def warn(self,ctxt,publisher_id,event_type,payload,metadata): print('in class warning') # other methods ","date":"2016-08-03","objectID":"/amqp/:3:1","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"测试样例 Client与Server Server代码(假设rabbitmq端口是:5672),我们创建了两个Endpoints,他们都绑定到了topictest下面，有着不同的namespace，我们在客户端可以通过不同的namespace指定具体的endpoint: import sys import logging from oslo_config import cfg import oslo_messaging as messaging class TestEndpoint(object): target = messaging.Target(namespace='namespace1', version='1.0') def test(self,ctx,arg): print('this is in text endpoint') return arg class AnotherTestEndpoint(object): target = messaging.Target(namespace='namespace2', version='1.0') def test(self,ctx,arg): print('this is in another text endpoint') return arg transport = messaging.get_transport(cfg.CONF,url='rabbit://127.0.0.1:5672/') target = messaging.Target(topic='test',server='server1') endpoints = [TestEndpoint(),AnotherTestEndpoint()] server = messaging.get_rpc_server(transport,target,endpoints,executor='blocking') server.start() server.wait() client代码: from oslo_config import cfg import oslo_messaging as messaging transport = messaging.get_transport(cfg.CONF,url='rabbit://127.0.0.1:5672/') target = messaging.Target(topic='test',server='server1',namespace='namespace2',fanout=True) client = messaging.RPCClient(transport,target) ret = client.cast(ctxt={},method='test',arg = 'this is text') 我们使用cast调用服务端的接口，所以实际执行的时候，程序会等待AnotherTestEndpoint.test接口执行完毕，并获取到最终的返回值。 Notification Listener和Notifier Notification Listener代码: from oslo_config import cfg import oslo_messaging as messaging class NotificationEndpoint(object): def warn(self,ctxt,publisher_id,event_type,payload,metadata): print('in class warning') return messaging.NotificationResult.HANDLED class ErrorEndpoint(object): def error(self, ctxt, publisher_id, event_type, payload, metadata): print('in class error') return messaging.NotificationResult.HANDLED transport = messaging.get_transport(cfg.CONF,url='rabbit://127.0.0.1:5672/') targets = [ messaging.Target(topic='notification_1'), messaging.Target(topic='notification_2') ] endpoints = [NotificationEndpoint(),ErrorEndpoint()] server = messaging.get_notification_listener(transport,targets,endpoints) server.start() server.wait() Notifier代码: from oslo_config import cfg import oslo_messaging as messaging transport = messaging.get_transport(cfg.CONF,url='rabbit://127.0.0.1:5672/') notifier = messaging.Notifier(transport,driver='messaging',topic='notification_3') notifier.error(ctxt={},event_type='this is type',payload={'hello': 'world'}) notifier.warn(ctxt={},event_type='this is type',payload={'hello': 'world'}) Notification listenser在实现的时候直接对应消息级别，比如 warning, error 等，在这个样例中，我们的ErrorEndpoint和NotificationEndpoint会依次被调用，需要注意这里不会等待执行完成。 ","date":"2016-08-03","objectID":"/amqp/:3:2","tags":["OpenStack","AMQP","RPC"],"title":"Oslo Message 入门","uri":"/amqp/"},{"categories":["OpenStack"],"content":"Paste Deploy 入门 ","date":"2016-08-03","objectID":"/paste-deploy/:0:0","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"什么是Paste Deploy Paste Depoly是一个用于发现和配置WSGI application和server的系统,以下是官方对PasteDeploy的定义: Paste Deployment is a system for finding and configuring WSGI applications and servers. For WSGI application consumers it provides a single, simple function (loadapp) for loading a WSGI application from a configuration file or a Python Egg. For WSGI application providers it only asks for a single, simple entry point to your application, so that application users don’t need to be exposed to the implementation details of your application. 最主要的就是能快速构建复杂且独立的WSGI程序，还能屏蔽具体的实现。 ","date":"2016-08-03","objectID":"/paste-deploy/:1:0","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"安装Paste Deploy PasteDeploy已经从Paste库中剥离出来，可以单独安装: sudo pip install PasteDeploy ","date":"2016-08-03","objectID":"/paste-deploy/:2:0","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"Paste Deploy 服务加载 使用PasteDeploy加载服务非常简单，大致的代码如下: import os from paste.deploy import loadapp from wsgiref.simple_server import make_server config_path = os.path.abspath('config.ini') appname='test_app' wsgi_app = loadapp('config:%s' % 'config.ini', appname,relative_to=os.getcwd()) server = make_server('localhost', 8080, wsgi_app) server.serve_forever() 使用loadapp指定配置文加载app最终放入server即可，需要注意的是: appname即你需要执行的application名，需要与配置文件中的名称保持一致( [composite:xxxx] ) load_app需要指定配置文件的绝对路径，如果是相对路径，需要通过 relative_to 来指定相对的目录 配置文件需要类似 config:absolute_path 格式 ","date":"2016-08-03","objectID":"/paste-deploy/:3:0","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"Config 配置解析 配置文件使用**.INI(initialize)**的文件格式，在ini文件中一般使用键值对的方式进行配置: name=value 配置文件中可以使用**;或者#**作为注释符(必须在行首)，配置文件一般如下所示: #this is a comment [composite:main] use = egg:Paste#urlmap / = home /blog = blog /wiki = wiki /cms = config:cms.ini ;this is another comment [app:home] use = egg:Paste#static document_root = %(here)s/htdocs [filter-app:blog] use = egg:Authentication#auth next = blogapp roles = admin htpasswd = /home/me/users.htpasswd [app:blogapp] use = egg:BlogApp database = sqlite:/home/me/blog.db [app:wiki] use = call:mywiki.main:application database = sqlite:/home/me/wiki.db 文件中使用单行的 [] 将配置字段划分成多个区域(section)。Paste Deploy只关注有前缀的区域，格式一般如下所示: [composite:main] :前面表示该区域的类型，后面表示区域的名称，类型一般有 app,filter,pipeline,composition 等，下面以常见的类型做简单的介绍: ","date":"2016-08-03","objectID":"/paste-deploy/:4:0","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"composite composite可以理解成是一个application的组合器或者url的分发器，负责把不同的url分发到不同的application中： [composite:main] #即使用Paste中的urlmap模块进行url映射分发 use = egg:Paste#urlmap #指向本配置文件中的home app / = home #指向本配置文件中的blog app /blog = blog #指向本配置文件中的wiki app /wiki = wiki #指向同级目录的另一个配置文件，作为二级app挂在到/cms下 /cms = config:cms.ini ","date":"2016-08-03","objectID":"/paste-deploy/:4:1","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"app 即application，app可以支持多种不同的应用，通过以下几种举例: 通过.ini文件指向另一个配置文件里的应用 [app:configapp] use = config:another_config_file.ini#config_name 指向Egg封装的应用 [app:eggapp] use = egg:AnotherApp 指向模块中的应用 [app:moduleapp] use = call:another_module:app 指向配置文件中的其他app [app:sectioneapp] use=antoher_section_app 指向paste/factory配置的app [app:factoryapp] paste.app_factory = module_a.class_b.factory 指向静态资源路径 [app:staticsfolder] use = egg:Paste#static document_root = %(here)s/htdocs 这里使用%()s用于动态载入实际目录 ","date":"2016-08-03","objectID":"/paste-deploy/:4:2","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"filter 即过滤器，快速构建AOP模块，通常用来做校验，日志等，我们通过以下几种类型举例: 1.使用filter-with对指定app进行过滤 [filter-app:blog] use = egg:Authentication#baseauth next = blogapp 以上配置中通过use和next，指明使用baseauthfilter对blogapp进行过滤 2.直接使用filter-with指定过滤器 [app:main] use = egg:MyEgg filter-with = printdebug [filter:printdebug] use = egg:Paste#printdebug 跟第一种方式比起来，filter-app能够快速被多个application复用。 3.使用pipeline快速建立多级过滤 [pipeline:main] pipeline = filter1 egg:FilterEgg#filter2 filter3 app 需要注意的事，这里通过**pipeline=**指定具体的过滤，可以指定多个，配置的先后顺序就是依次通过的顺序，但是必须要以一个application作为末尾节点。 ","date":"2016-08-03","objectID":"/paste-deploy/:4:3","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"Config Variables 配置文件中支持配置全局或者局部变量，这些字段会在构建app的过程中作为参数传入,实例如下: [DEFAULT] key_one = value key_another = value [app:another] key_section = value 在局部的配置中支持对变量进行覆盖重定义,使用关键字set [app:another] set key_one = new_value ","date":"2016-08-03","objectID":"/paste-deploy/:4:4","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"Factories Factories即我们的App/Filter生成器，需要遵守协议和规范定义，根据用途的不同，可以分为以下几种: 1.app_factory 生成标准的WSGI application，规范如下 def app_factory(global_config, **local_conf): return wsgi_app 传入的参数:global_config和local_conf，分别对应我们的不同配置变量,以我们上面的配置文件举例，那实际传入的值如下: #一般还会有其他字段,如__file__ global_config = {key_one:value,key_another:value,...} local_conf = {key_section:value} 举一个实际的例子，加入我们现在要定义一个application，计算传入的param1和param2的和，并返回最终的和: from webob import Request class Calculator: def __init__(self): pass def __call__(self, environ, start_response): req = Request(environ) param1 = int(req.GET.get(\"param1\", None)) param2 = int(req.GET.get(\"param2\", None)) start_response(\"200 OK\",[(\"Content-type\", \"text/plain\")]) return [\"RESULT={0}\".format(param1+param2).encode('utf-8')] @classmethod def factory(cls, global_conf, **local_conf): return Calculator() #config files [app:calculator] paste.app_factory = tommylike:Calculator.factory 2.filter_factory 跟我们的app_factory差不多，区别在于他接受的是一个WSGI app，同样假设我们要定义一个filter-app,用来做日志拦截记录: class LogFilter: def __init__(self, app): self.app = app def __call__(self, environ, start_response): print(\"Log Filter\") return self.app(environ,start_response) @classmethod def factory(cls, global_conf, **kwargs): return LogFilter #config files [filter:apilog] paste.filter_factory = tommylike:LogFilter.factory 3.filter_app_factory 跟filter_factory相比，传入的参数多了一个app,可以借用上面的例子比较下 #used for filter_factory @classmethod def factory(cls, global_conf, **kwargs): return LogFilter1 #used for filter_app_factory @classmethod def factory(cls,app, global_conf, **kwargs): return LogFilter2(app) 4. filter_server 接受一个app，并返回封装这个app的server，举例代码如下 def server_factory(global_conf, host, port): port = int(port) def serve(app): s = Server(app, host=host, port=port) s.serve_forever() return serve 5. server_factory 与filter_server差不多，区别在于server会马上拉起来，并且app是作为第一个参数传入,根filter_factory与filter_app_factory的区别一致。 ","date":"2016-08-03","objectID":"/paste-deploy/:4:5","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"Oslo.middleware 在Openstack中middleware提供了内置的filter以便我们方便取用，目前主要有两种filter，healthcheck和cors middleware ","date":"2016-08-03","objectID":"/paste-deploy/:4:6","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"安装 oslo.middleware目前是独立的组件，可以直接安装 sudo pip install oslo.middleware ","date":"2016-08-03","objectID":"/paste-deploy/:4:7","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"healthcheck middleware healthcheck middleware主要用于服务的健康状态检查，根据后端是否正常，返回200(服务正常)/503(服务不可用)配置文件如下: [filter:healthcheck] paste.filter_factory = oslo_middleware:Healthcheck.factory path = /healthcheck backends = disable_by_file disable_by_file_path = /var/run/nova/healthcheck_disable [pipeline:public_api] pipeline = healthcheck sizelimit [...] public_service 其中 paste.filter_factory指明使用oslo_middleware中的healthcheck，path用来指明检测的具体url：{resource}/healthcheck,backends用来指定后端的判定方式，目前有两种： 使用文件是否存在来检测，配置如下: [filter:healthcheck] #other config #指明使用文件来校验 backends = disable_by_file #指明具体的文件，文件如果存在，healthcheck任务后端返回异常 disable_by_file_path = /var/run/nova/healthcheck_disable 使用文件以及端口检测，配置如下: [filter:healthcheck] #other configs #指明文件以及端口校验 backends = disable_by_files_ports #指明具体的端口和文件 disable_by_file_paths = 5000:/var/run/keystone/healthcheck_disable, /35357:/var/run/keystone/admin_healthcheck_disable disable_by_file_paths可以指明多个端口和对应的文件，根据访问的端口进行校验，比如当前端口是5000，则根据文件*/var/run/keystone/healthcheck_disable*的存在与否决定服务是否健康，可以理解为disable_by_file的增强版本 ","date":"2016-08-03","objectID":"/paste-deploy/:4:8","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"},{"categories":["OpenStack"],"content":"cors middleware cors middlreware用来控制跨域访问控制，也可以直接在配置文件中配置: [filter:cors] paste.filter_factory = oslo_middleware.cors:filter_factory allowed_origin=https://website.example.com:443,https://website2.example.com:443 #设置允许跨域访问的站点和方式等。 max_age=3600 allow_methods=GET,POST,PUT,DELETE allow_headers=X-Custom-Header expose_headers=X-Custom-Header ","date":"2016-08-03","objectID":"/paste-deploy/:4:9","tags":["PasteDeploy","Python","OpenStack"],"title":"Paste Deploy 入门","uri":"/paste-deploy/"}]